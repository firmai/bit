<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Interpretable Machine Learning</title>
  <meta name="description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisions more interpretable.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Interpretable Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisions more interpretable." />
  <meta name="github-repo" content="christophM/interpretable-ml-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Interpretable Machine Learning" />
  
  <meta name="twitter:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisions more interpretable." />
  

<meta name="author" content="Christoph Molnar">


<meta name="date" content="2018-10-14">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="limo.html">
<link rel="next" href="tree.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<!-- Global site tag (gtag.js) - Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-110543840-1', 'https://christophm.github.io/interpretable-ml-book/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>

<link rel="stylesheet" type="text/css" href="css/cookieconsent.min.css" />
<script src="javascript/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#000"
    },
    "button": {
      "background": "#f1d600"
    }
  },
  "position": "bottom-right",
  "content": {
    "message": "This website uses cookies for Google Analytics so that I know how many people are reading the book and which chapters are the most popular. The book website doesn't collect any personal data."
  }
})});
</script>



<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Interpretable machine learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="storytime.html"><a href="storytime.html"><i class="fa fa-check"></i><b>2.1</b> Storytime</a><ul>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#lightning-never-strikes-twice"><i class="fa fa-check"></i>Lightning Never Strikes Twice</a></li>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#trust-fall"><i class="fa fa-check"></i>Trust Fall</a></li>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#fermis-paperclips"><i class="fa fa-check"></i>Fermi’s Paperclips</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html"><i class="fa fa-check"></i><b>2.2</b> What Is Machine Learning?</a></li>
<li class="chapter" data-level="2.3" data-path="definitions.html"><a href="definitions.html"><i class="fa fa-check"></i><b>2.3</b> Definitions</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="interpretability.html"><a href="interpretability.html"><i class="fa fa-check"></i><b>3</b> Interpretability</a><ul>
<li class="chapter" data-level="3.1" data-path="interpretability-importance.html"><a href="interpretability-importance.html"><i class="fa fa-check"></i><b>3.1</b> The Importance of Interpretability</a></li>
<li class="chapter" data-level="3.2" data-path="criteria-for-interpretability-methods.html"><a href="criteria-for-interpretability-methods.html"><i class="fa fa-check"></i><b>3.2</b> Criteria for Interpretability Methods</a></li>
<li class="chapter" data-level="3.3" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html"><i class="fa fa-check"></i><b>3.3</b> Scope of Interpretability</a><ul>
<li class="chapter" data-level="3.3.1" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#algorithm-transparency"><i class="fa fa-check"></i><b>3.3.1</b> Algorithm transparency</a></li>
<li class="chapter" data-level="3.3.2" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-holistic-model-interpretability"><i class="fa fa-check"></i><b>3.3.2</b> Global, Holistic Model Interpretability</a></li>
<li class="chapter" data-level="3.3.3" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-model-interpretability-on-a-modular-level"><i class="fa fa-check"></i><b>3.3.3</b> Global Model Interpretability on a Modular Level</a></li>
<li class="chapter" data-level="3.3.4" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#local-interpretability-for-a-single-prediction"><i class="fa fa-check"></i><b>3.3.4</b> Local Interpretability for a Single Prediction</a></li>
<li class="chapter" data-level="3.3.5" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#local-interpretability-for-a-group-of-predictions"><i class="fa fa-check"></i><b>3.3.5</b> Local Interpretability for a Group of Predictions</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="evaluating-interpretability.html"><a href="evaluating-interpretability.html"><i class="fa fa-check"></i><b>3.4</b> Evaluating Interpretability</a></li>
<li class="chapter" data-level="3.5" data-path="explanation.html"><a href="explanation.html"><i class="fa fa-check"></i><b>3.5</b> Human-friendly Explanations</a><ul>
<li class="chapter" data-level="3.5.1" data-path="explanation.html"><a href="explanation.html#what-is-an-explanation"><i class="fa fa-check"></i><b>3.5.1</b> What is an explanation?</a></li>
<li class="chapter" data-level="3.5.2" data-path="explanation.html"><a href="explanation.html#good-explanation"><i class="fa fa-check"></i><b>3.5.2</b> What is a “good” explanation?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>4</b> Datasets</a><ul>
<li class="chapter" data-level="4.1" data-path="bike-data.html"><a href="bike-data.html"><i class="fa fa-check"></i><b>4.1</b> Bike Sharing Counts (Regression)</a></li>
<li class="chapter" data-level="4.2" data-path="spam-data.html"><a href="spam-data.html"><i class="fa fa-check"></i><b>4.2</b> YouTube Spam Comments (Text Classification)</a></li>
<li class="chapter" data-level="4.3" data-path="cervical.html"><a href="cervical.html"><i class="fa fa-check"></i><b>4.3</b> Risk Factors for Cervical Cancer (Classification)</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="simple.html"><a href="simple.html"><i class="fa fa-check"></i><b>5</b> Interpretable Models</a><ul>
<li class="chapter" data-level="5.1" data-path="limo.html"><a href="limo.html"><i class="fa fa-check"></i><b>5.1</b> Linear Model</a><ul>
<li class="chapter" data-level="5.1.1" data-path="limo.html"><a href="limo.html#interpretation"><i class="fa fa-check"></i><b>5.1.1</b> Interpretation</a></li>
<li class="chapter" data-level="5.1.2" data-path="limo.html"><a href="limo.html#interpretation-example"><i class="fa fa-check"></i><b>5.1.2</b> Interpretation Example</a></li>
<li class="chapter" data-level="5.1.3" data-path="limo.html"><a href="limo.html#interpretation-templates"><i class="fa fa-check"></i><b>5.1.3</b> Interpretation templates</a></li>
<li class="chapter" data-level="5.1.4" data-path="limo.html"><a href="limo.html#visual-parameter-interpretation"><i class="fa fa-check"></i><b>5.1.4</b> Visual parameter interpretation</a></li>
<li class="chapter" data-level="5.1.5" data-path="limo.html"><a href="limo.html#explaining-single-predictions"><i class="fa fa-check"></i><b>5.1.5</b> Explaining Single Predictions</a></li>
<li class="chapter" data-level="5.1.6" data-path="limo.html"><a href="limo.html#cat-code"><i class="fa fa-check"></i><b>5.1.6</b> Coding Categorical Features</a></li>
<li class="chapter" data-level="5.1.7" data-path="limo.html"><a href="limo.html#the-disadvantages-of-linear-models"><i class="fa fa-check"></i><b>5.1.7</b> The disadvantages of linear models</a></li>
<li class="chapter" data-level="5.1.8" data-path="limo.html"><a href="limo.html#do-linear-models-create-good-explanations"><i class="fa fa-check"></i><b>5.1.8</b> Do linear models create good explanations?</a></li>
<li class="chapter" data-level="5.1.9" data-path="limo.html"><a href="limo.html#extending-linear-models"><i class="fa fa-check"></i><b>5.1.9</b> Extending Linear Models</a></li>
<li class="chapter" data-level="5.1.10" data-path="limo.html"><a href="limo.html#sparse-linear"><i class="fa fa-check"></i><b>5.1.10</b> Sparse linear models</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="logistic.html"><a href="logistic.html"><i class="fa fa-check"></i><b>5.2</b> Logistic Regression</a><ul>
<li class="chapter" data-level="5.2.1" data-path="logistic.html"><a href="logistic.html#whats-wrong-with-linear-regression-models-for-classification"><i class="fa fa-check"></i><b>5.2.1</b> What’s Wrong with Linear Regression Models for Classification?</a></li>
<li class="chapter" data-level="5.2.2" data-path="logistic.html"><a href="logistic.html#logistic-regression"><i class="fa fa-check"></i><b>5.2.2</b> Logistic Regression</a></li>
<li class="chapter" data-level="5.2.3" data-path="logistic.html"><a href="logistic.html#interpretation-1"><i class="fa fa-check"></i><b>5.2.3</b> Interpretation</a></li>
<li class="chapter" data-level="5.2.4" data-path="logistic.html"><a href="logistic.html#example"><i class="fa fa-check"></i><b>5.2.4</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="tree.html"><a href="tree.html"><i class="fa fa-check"></i><b>5.3</b> Decision Tree</a><ul>
<li class="chapter" data-level="5.3.1" data-path="tree.html"><a href="tree.html#interpretation-2"><i class="fa fa-check"></i><b>5.3.1</b> Interpretation</a></li>
<li class="chapter" data-level="5.3.2" data-path="tree.html"><a href="tree.html#interpretation-example-1"><i class="fa fa-check"></i><b>5.3.2</b> Interpretation Example</a></li>
<li class="chapter" data-level="5.3.3" data-path="tree.html"><a href="tree.html#advantages"><i class="fa fa-check"></i><b>5.3.3</b> Advantages</a></li>
<li class="chapter" data-level="5.3.4" data-path="tree.html"><a href="tree.html#disadvantages"><i class="fa fa-check"></i><b>5.3.4</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="rules.html"><a href="rules.html"><i class="fa fa-check"></i><b>5.4</b> Decision Rules (IF-THEN)</a><ul>
<li class="chapter" data-level="5.4.1" data-path="rules.html"><a href="rules.html#learn-rules-from-a-single-feature-oner"><i class="fa fa-check"></i><b>5.4.1</b> Learn Rules from a Single Feature (OneR)</a></li>
<li class="chapter" data-level="5.4.2" data-path="rules.html"><a href="rules.html#sequential-covering"><i class="fa fa-check"></i><b>5.4.2</b> Sequential Covering</a></li>
<li class="chapter" data-level="5.4.3" data-path="rules.html"><a href="rules.html#bayesian-rule-lists"><i class="fa fa-check"></i><b>5.4.3</b> Bayesian Rule Lists</a></li>
<li class="chapter" data-level="5.4.4" data-path="rules.html"><a href="rules.html#advantages-1"><i class="fa fa-check"></i><b>5.4.4</b> Advantages</a></li>
<li class="chapter" data-level="5.4.5" data-path="rules.html"><a href="rules.html#disadvantages-1"><i class="fa fa-check"></i><b>5.4.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.4.6" data-path="rules.html"><a href="rules.html#software-and-alternatives"><i class="fa fa-check"></i><b>5.4.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="rulefit.html"><a href="rulefit.html"><i class="fa fa-check"></i><b>5.5</b> RuleFit</a><ul>
<li class="chapter" data-level="5.5.1" data-path="rulefit.html"><a href="rulefit.html#interpretation-and-example"><i class="fa fa-check"></i><b>5.5.1</b> Interpretation and Example</a></li>
<li class="chapter" data-level="5.5.2" data-path="rulefit.html"><a href="rulefit.html#guidelines"><i class="fa fa-check"></i><b>5.5.2</b> Guidelines</a></li>
<li class="chapter" data-level="5.5.3" data-path="rulefit.html"><a href="rulefit.html#theory"><i class="fa fa-check"></i><b>5.5.3</b> Theory</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="other-interpretable.html"><a href="other-interpretable.html"><i class="fa fa-check"></i><b>5.6</b> Other Interpretable Models</a><ul>
<li class="chapter" data-level="5.6.1" data-path="other-interpretable.html"><a href="other-interpretable.html#naive-bayes-classifier"><i class="fa fa-check"></i><b>5.6.1</b> Naive Bayes classifier</a></li>
<li class="chapter" data-level="5.6.2" data-path="other-interpretable.html"><a href="other-interpretable.html#k-nearest-neighbours"><i class="fa fa-check"></i><b>5.6.2</b> K-Nearest Neighbours</a></li>
<li class="chapter" data-level="5.6.3" data-path="other-interpretable.html"><a href="other-interpretable.html#and-so-many-more"><i class="fa fa-check"></i><b>5.6.3</b> And so many more …</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="agnostic.html"><a href="agnostic.html"><i class="fa fa-check"></i><b>6</b> Model-Agnostic Methods</a><ul>
<li class="chapter" data-level="6.1" data-path="pdp.html"><a href="pdp.html"><i class="fa fa-check"></i><b>6.1</b> Partial Dependence Plot (PDP)</a><ul>
<li class="chapter" data-level="6.1.1" data-path="pdp.html"><a href="pdp.html#examples"><i class="fa fa-check"></i><b>6.1.1</b> Examples</a></li>
<li class="chapter" data-level="6.1.2" data-path="pdp.html"><a href="pdp.html#advantages-2"><i class="fa fa-check"></i><b>6.1.2</b> Advantages</a></li>
<li class="chapter" data-level="6.1.3" data-path="pdp.html"><a href="pdp.html#disadvantages-2"><i class="fa fa-check"></i><b>6.1.3</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="ice.html"><a href="ice.html"><i class="fa fa-check"></i><b>6.2</b> Individual Conditional Expectation (ICE)</a><ul>
<li class="chapter" data-level="6.2.1" data-path="ice.html"><a href="ice.html#example-1"><i class="fa fa-check"></i><b>6.2.1</b> Example</a></li>
<li class="chapter" data-level="6.2.2" data-path="ice.html"><a href="ice.html#advantages-3"><i class="fa fa-check"></i><b>6.2.2</b> Advantages</a></li>
<li class="chapter" data-level="6.2.3" data-path="ice.html"><a href="ice.html#disadvantages-3"><i class="fa fa-check"></i><b>6.2.3</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="ale.html"><a href="ale.html"><i class="fa fa-check"></i><b>6.3</b> Accumulated Local Effects (ALE) Plot</a><ul>
<li class="chapter" data-level="6.3.1" data-path="ale.html"><a href="ale.html#motivation-and-intuition"><i class="fa fa-check"></i><b>6.3.1</b> Motivation and Intuition</a></li>
<li class="chapter" data-level="6.3.2" data-path="ale.html"><a href="ale.html#theory-1"><i class="fa fa-check"></i><b>6.3.2</b> Theory</a></li>
<li class="chapter" data-level="6.3.3" data-path="ale.html"><a href="ale.html#estimation"><i class="fa fa-check"></i><b>6.3.3</b> Estimation</a></li>
<li class="chapter" data-level="6.3.4" data-path="ale.html"><a href="ale.html#examples-1"><i class="fa fa-check"></i><b>6.3.4</b> Examples</a></li>
<li class="chapter" data-level="6.3.5" data-path="ale.html"><a href="ale.html#advantages-4"><i class="fa fa-check"></i><b>6.3.5</b> Advantages</a></li>
<li class="chapter" data-level="6.3.6" data-path="ale.html"><a href="ale.html#disadvantages-4"><i class="fa fa-check"></i><b>6.3.6</b> Disadvantages</a></li>
<li class="chapter" data-level="6.3.7" data-path="ale.html"><a href="ale.html#implementation-and-alternatives"><i class="fa fa-check"></i><b>6.3.7</b> Implementation and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="interaction.html"><a href="interaction.html"><i class="fa fa-check"></i><b>6.4</b> Feature Interaction</a><ul>
<li class="chapter" data-level="6.4.1" data-path="interaction.html"><a href="interaction.html#feature-interaction"><i class="fa fa-check"></i><b>6.4.1</b> Feature Interaction?</a></li>
<li class="chapter" data-level="6.4.2" data-path="interaction.html"><a href="interaction.html#theory-friedmans-h-statistic"><i class="fa fa-check"></i><b>6.4.2</b> Theory: Friedman’s H-statistic</a></li>
<li class="chapter" data-level="6.4.3" data-path="interaction.html"><a href="interaction.html#examples-2"><i class="fa fa-check"></i><b>6.4.3</b> Examples</a></li>
<li class="chapter" data-level="6.4.4" data-path="interaction.html"><a href="interaction.html#advantages-5"><i class="fa fa-check"></i><b>6.4.4</b> Advantages</a></li>
<li class="chapter" data-level="6.4.5" data-path="interaction.html"><a href="interaction.html#disadvantages-5"><i class="fa fa-check"></i><b>6.4.5</b> Disadvantages</a></li>
<li class="chapter" data-level="6.4.6" data-path="interaction.html"><a href="interaction.html#implementations"><i class="fa fa-check"></i><b>6.4.6</b> Implementations</a></li>
<li class="chapter" data-level="6.4.7" data-path="interaction.html"><a href="interaction.html#alternatives"><i class="fa fa-check"></i><b>6.4.7</b> Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="feature-importance.html"><a href="feature-importance.html"><i class="fa fa-check"></i><b>6.5</b> Feature Importance</a><ul>
<li class="chapter" data-level="6.5.1" data-path="feature-importance.html"><a href="feature-importance.html#the-theory"><i class="fa fa-check"></i><b>6.5.1</b> The Theory</a></li>
<li class="chapter" data-level="6.5.2" data-path="feature-importance.html"><a href="feature-importance.html#example-and-interpretation"><i class="fa fa-check"></i><b>6.5.2</b> Example and Interpretation</a></li>
<li class="chapter" data-level="6.5.3" data-path="feature-importance.html"><a href="feature-importance.html#advantages-6"><i class="fa fa-check"></i><b>6.5.3</b> Advantages</a></li>
<li class="chapter" data-level="6.5.4" data-path="feature-importance.html"><a href="feature-importance.html#disadvantages-6"><i class="fa fa-check"></i><b>6.5.4</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="global.html"><a href="global.html"><i class="fa fa-check"></i><b>6.6</b> Global Surrogate Models</a><ul>
<li class="chapter" data-level="6.6.1" data-path="global.html"><a href="global.html#theory-2"><i class="fa fa-check"></i><b>6.6.1</b> Theory</a></li>
<li class="chapter" data-level="6.6.2" data-path="global.html"><a href="global.html#example-3"><i class="fa fa-check"></i><b>6.6.2</b> Example</a></li>
<li class="chapter" data-level="6.6.3" data-path="global.html"><a href="global.html#advantages-7"><i class="fa fa-check"></i><b>6.6.3</b> Advantages</a></li>
<li class="chapter" data-level="6.6.4" data-path="global.html"><a href="global.html#disadvantages-7"><i class="fa fa-check"></i><b>6.6.4</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="lime.html"><a href="lime.html"><i class="fa fa-check"></i><b>6.7</b> Local Surrogate Models (LIME)</a><ul>
<li class="chapter" data-level="6.7.1" data-path="lime.html"><a href="lime.html#lime-for-tabular-data"><i class="fa fa-check"></i><b>6.7.1</b> LIME for Tabular Data</a></li>
<li class="chapter" data-level="6.7.2" data-path="lime.html"><a href="lime.html#lime-for-text"><i class="fa fa-check"></i><b>6.7.2</b> LIME for Text</a></li>
<li class="chapter" data-level="6.7.3" data-path="lime.html"><a href="lime.html#images-lime"><i class="fa fa-check"></i><b>6.7.3</b> LIME for Images</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>6.8</b> Shapley Value Explanations</a><ul>
<li class="chapter" data-level="6.8.1" data-path="shapley.html"><a href="shapley.html#the-general-idea"><i class="fa fa-check"></i><b>6.8.1</b> The general idea</a></li>
<li class="chapter" data-level="6.8.2" data-path="shapley.html"><a href="shapley.html#examples-and-interpretation"><i class="fa fa-check"></i><b>6.8.2</b> Examples and Interpretation</a></li>
<li class="chapter" data-level="6.8.3" data-path="shapley.html"><a href="shapley.html#the-shapley-value-in-detail"><i class="fa fa-check"></i><b>6.8.3</b> The Shapley Value in Detail</a></li>
<li class="chapter" data-level="6.8.4" data-path="shapley.html"><a href="shapley.html#advantages-8"><i class="fa fa-check"></i><b>6.8.4</b> Advantages</a></li>
<li class="chapter" data-level="6.8.5" data-path="shapley.html"><a href="shapley.html#disadvantages-8"><i class="fa fa-check"></i><b>6.8.5</b> Disadvantages</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="example-based.html"><a href="example-based.html"><i class="fa fa-check"></i><b>7</b> Example-based Explanations</a><ul>
<li class="chapter" data-level="7.1" data-path="counterfactual.html"><a href="counterfactual.html"><i class="fa fa-check"></i><b>7.1</b> Counterfactual explanations</a><ul>
<li class="chapter" data-level="7.1.1" data-path="counterfactual.html"><a href="counterfactual.html#generating-counterfactual-explanations"><i class="fa fa-check"></i><b>7.1.1</b> Generating counterfactual explanations</a></li>
<li class="chapter" data-level="7.1.2" data-path="counterfactual.html"><a href="counterfactual.html#examples-3"><i class="fa fa-check"></i><b>7.1.2</b> Examples</a></li>
<li class="chapter" data-level="7.1.3" data-path="counterfactual.html"><a href="counterfactual.html#advantages-9"><i class="fa fa-check"></i><b>7.1.3</b> Advantages</a></li>
<li class="chapter" data-level="7.1.4" data-path="counterfactual.html"><a href="counterfactual.html#disadvantages-9"><i class="fa fa-check"></i><b>7.1.4</b> Disadvantages</a></li>
<li class="chapter" data-level="7.1.5" data-path="counterfactual.html"><a href="counterfactual.html#example-software"><i class="fa fa-check"></i><b>7.1.5</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="adversarial.html"><a href="adversarial.html"><i class="fa fa-check"></i><b>7.2</b> Adversarial Examples</a><ul>
<li class="chapter" data-level="7.2.1" data-path="adversarial.html"><a href="adversarial.html#methods-and-examples"><i class="fa fa-check"></i><b>7.2.1</b> Methods and Examples</a></li>
<li class="chapter" data-level="7.2.2" data-path="adversarial.html"><a href="adversarial.html#the-cybersecurity-perspective"><i class="fa fa-check"></i><b>7.2.2</b> The Cybersecurity Perspective</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="proto.html"><a href="proto.html"><i class="fa fa-check"></i><b>7.3</b> Prototypes and Criticisms</a><ul>
<li class="chapter" data-level="7.3.1" data-path="proto.html"><a href="proto.html#theory-3"><i class="fa fa-check"></i><b>7.3.1</b> Theory</a></li>
<li class="chapter" data-level="7.3.2" data-path="proto.html"><a href="proto.html#examples-4"><i class="fa fa-check"></i><b>7.3.2</b> Examples</a></li>
<li class="chapter" data-level="7.3.3" data-path="proto.html"><a href="proto.html#advantages-10"><i class="fa fa-check"></i><b>7.3.3</b> Advantages</a></li>
<li class="chapter" data-level="7.3.4" data-path="proto.html"><a href="proto.html#disadvantages-10"><i class="fa fa-check"></i><b>7.3.4</b> Disadvantages</a></li>
<li class="chapter" data-level="7.3.5" data-path="proto.html"><a href="proto.html#code-and-alternatives"><i class="fa fa-check"></i><b>7.3.5</b> Code and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="influential.html"><a href="influential.html"><i class="fa fa-check"></i><b>7.4</b> Influential Instances</a><ul>
<li class="chapter" data-level="7.4.1" data-path="influential.html"><a href="influential.html#deletion-diagnostics"><i class="fa fa-check"></i><b>7.4.1</b> Deletion Diagnostics</a></li>
<li class="chapter" data-level="7.4.2" data-path="influential.html"><a href="influential.html#influence-functions"><i class="fa fa-check"></i><b>7.4.2</b> Influence Functions</a></li>
<li class="chapter" data-level="7.4.3" data-path="influential.html"><a href="influential.html#advantages-of-identifying-influential-instances"><i class="fa fa-check"></i><b>7.4.3</b> Advantages of Identifying Influential Instances</a></li>
<li class="chapter" data-level="7.4.4" data-path="influential.html"><a href="influential.html#disadvantages-of-identifying-influential-instances"><i class="fa fa-check"></i><b>7.4.4</b> Disadvantages of Identifying Influential Instances</a></li>
<li class="chapter" data-level="7.4.5" data-path="influential.html"><a href="influential.html#software-and-alternatives-1"><i class="fa fa-check"></i><b>7.4.5</b> Software and Alternatives</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="future.html"><a href="future.html"><i class="fa fa-check"></i><b>8</b> A Look into the Crystal Ball</a><ul>
<li class="chapter" data-level="8.1" data-path="the-future-of-machine-learning.html"><a href="the-future-of-machine-learning.html"><i class="fa fa-check"></i><b>8.1</b> The Future of Machine Learning</a></li>
<li class="chapter" data-level="8.2" data-path="the-future-of-interpretability.html"><a href="the-future-of-interpretability.html"><i class="fa fa-check"></i><b>8.2</b> The Future of Interpretability</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="contribute.html"><a href="contribute.html"><i class="fa fa-check"></i><b>9</b> Contribute</a></li>
<li class="chapter" data-level="10" data-path="citation.html"><a href="citation.html"><i class="fa fa-check"></i><b>10</b> Citation</a></li>
<li class="chapter" data-level="11" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i><b>11</b> Acknowledgements</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interpretable Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="logistic" class="section level2">
<h2><span class="header-section-number">5.2</span> Logistic Regression</h2>
<p>Logistic regression is the linear regression model made fit for classification problems.</p>
<div id="whats-wrong-with-linear-regression-models-for-classification" class="section level3">
<h3><span class="header-section-number">5.2.1</span> What’s Wrong with Linear Regression Models for Classification?</h3>
<p>The linear regression model works well in regression setups, but fails in the classification case.
Why is that?
In case of two classes, you could label one of the classes with 0 and the other with 1 and use a linear model on it and it would estimate the weights for you.
There are just a few problems with that approach:</p>
<ul>
<li>A linear model does not output probabilities, but it treats the classes as numbers (0 and 1) and fits the best hyperplane (if you have one feature, it’s a line) that minimises the distances between the points and the hyperplane.
So it simply interpolates between the points, but there is no meaning in it and you cannot interpret it as probabilities.</li>
<li>Also a linear model will extrapolate the features and give you values below zero and above one, which are not meaningful and should tell you that there might be a more clever approach to classification.</li>
<li>Since the predicted outcome is not a probability but some linear interpolation between points there is no meaningful threshold at which you can distinguish one class from the other.
A good illustration of this issue was given on <a href="https://stats.stackexchange.com/questions/22381/why-not-approach-classification-through-regression">Stackoverflow</a></li>
<li>Linear models don’t extend to classification problems with multiple classes.
You would have to start labeling the next class with a 2, then 3 and so on.
The classes might not have any meaningful order, but the linear model would force a weird structure on the relationship between the features and your class predictions.
So for a feature with a positive weight, the higher the value of that feature the more it contributes to the prediction of a class with a higher number, even if classes that happened to get a similar number are not related at all.</li>
</ul>
<div class="figure"><span id="fig:linear-class-threshold"></span>
<img src="images/linear-class-threshold-1.png" alt="An illustration why linear regression does not work well in a binary classification setting. A linear model is fitted on artificial data for classifying a tumour as malignant (1) or benign (0), dependant on the size of the tumour. Each point is a tumour, the x-axis shows the size of the tumour, the y-axis the malignancy, points are slightly jittered to reduce over-plotting. The lines display the fitted curve from a linear model. In the data setting on the left, we can use 0.5 as a threshold for the predicted outcome of the linear model for separating benign from malignant tumours. After introducing a few more malignant tumour cases, especially with larger tumour sizes, the regression line shifts and a threshold of 0.5 does not separate the classes any longer." width="1050" />
<p class="caption">
FIGURE 5.4: An illustration why linear regression does not work well in a binary classification setting. A linear model is fitted on artificial data for classifying a tumour as malignant (1) or benign (0), dependant on the size of the tumour. Each point is a tumour, the x-axis shows the size of the tumour, the y-axis the malignancy, points are slightly jittered to reduce over-plotting. The lines display the fitted curve from a linear model. In the data setting on the left, we can use 0.5 as a threshold for the predicted outcome of the linear model for separating benign from malignant tumours. After introducing a few more malignant tumour cases, especially with larger tumour sizes, the regression line shifts and a threshold of 0.5 does not separate the classes any longer.
</p>
</div>
</div>
<div id="logistic-regression" class="section level3">
<h3><span class="header-section-number">5.2.2</span> Logistic Regression</h3>
<p>A solution for classification is logistic regression.
Instead of fitting a straight line or hyperplane, the logistic regression model uses a non-linear function, the logistic function to squeeze the output of a linear equation between 0 and 1.
The logistic function is defined as:</p>
<p><span class="math display">\[\text{logistic}(\eta)=\frac{1}{1+exp(-\eta)}\]</span></p>
<p>And it looks like this:</p>
<div class="figure"><span id="fig:logistic-function"></span>
<img src="images/logistic-function-1.png" alt="The logistic function. It only outputs numbers between 0 and 1. At input 0 it outputs 0.5." width="1050" />
<p class="caption">
FIGURE 5.5: The logistic function. It only outputs numbers between 0 and 1. At input 0 it outputs 0.5.
</p>
</div>
<p>The step from linear regression models to logistic regression is kind of straightforward. In the linear regression model we modelled the relationship between the outcome and the features with a linear equation:</p>
<p><span class="math display">\[\hat{y}_{i}=\beta_{0}+\beta_{1}x_{i,1}+\ldots+\beta_{p}x_{i,p}\]</span></p>
<p>For the classification we prefer probabilities, which are between 0 and 1, so we wrap the right side of the equation into the logistic regression function and like that force the output to only take on values between 0 and 1.</p>
<p><span class="math display">\[P(y_{i}=1)=\frac{1}{1+exp(-(\beta_{0}+\beta_{1}x_{i,1}+\ldots+\beta_{p}x_{i,p}))}\]</span></p>
<p>Let’s revisit the tumour size example again.
But instead of the linear regression model, we use the logistic regression model:</p>
<div class="figure"><span id="fig:logistic-class-threshold"></span>
<img src="images/logistic-class-threshold-1.png" alt="The logistic regression model successfully finds the correct decision boundary to distinguish between malignant and benign tumours dependent on the size of the tumour in this example. The blue line is the logistic function shifted and squeezed so that it fits the data." width="1050" />
<p class="caption">
FIGURE 5.6: The logistic regression model successfully finds the correct decision boundary to distinguish between malignant and benign tumours dependent on the size of the tumour in this example. The blue line is the logistic function shifted and squeezed so that it fits the data.
</p>
</div>
<p>It works better with logistic regression and we can use 0.5 as a threshold in both cases. Including the additional points does not affect the estimated curve much.</p>
</div>
<div id="interpretation-1" class="section level3">
<h3><span class="header-section-number">5.2.3</span> Interpretation</h3>
<p>The interpretation of the logistic regression weights differs from the linear regression case, because in logistic regression the outcome is a probability between 0 and 1, and the weights don’t affect the probability linearly, but are squeezed through the logistic function.
That’s why we need to reformulate the equation for the interpretation, so that there is only the linear term left on the right side of the formula.</p>
<p><span class="math display">\[log\left(\frac{P(y_{i}=1)}{1-P(y_{i}=1)}\right)=log\left(\frac{P(y_{i}=1)}{P(y_{i}=0)}\right)=\beta_{0}+\beta_{1}x_{i,1}+\ldots+\beta_{p}x_{i,p}\]</span></p>
<p>We call the inner term odds (probability of event divided by probability of no event):</p>
<p><span class="math display">\[\frac{P(y_{i}=1)}{1-P(y_{i}=1)}\]</span>
and wrapped in the logarithm it is called log odds:</p>
<p><span class="math display">\[log\left(\frac{P(y_{i}=1)}{1-P(y_{i}=1)}\right)\]</span></p>
<p>So with a logistic regression model we have a linear model for the log odds.
Great!
Doesn’t sound helpful!
Well, with a bit of shuffling again, you can find out how the prediction changes, when one of the features <span class="math inline">\(x_j\)</span> is changed by 1 point.
For this we can first apply the <span class="math inline">\(exp()\)</span> function on both sides of the equation:</p>
<p><span class="math display">\[\frac{P(y_{i}=1)}{(1-P(y_{i}=1))}=odds_i=exp\left(\beta_{0}+\beta_{1}x_{i,1}+\ldots+\beta_{p}x_{i,p}\right)\]</span></p>
<p>Then we compare what happens when we increase one of the <span class="math inline">\(x_{i,j}\)</span> by 1.
But instead of looking at the difference, we look at the ratio of the two predictions:</p>
<p><span class="math display">\[\frac{odds_{i,x_j+1}}{odds_i}=\frac{exp\left(\beta_{0}+\beta_{1}x_{i,1}+\ldots+\beta_{j}(x_{i,j}+1)+\ldots+\beta_{p}x_{i,p}\right)}{exp\left(\beta_{0}+\beta_{1}x_{i,1}+\ldots+\beta_{j}x_{i,j}+\ldots+\beta_{p}x_{i,p}\right)}\]</span></p>
<p>Using the rule that:</p>
<p><span class="math display">\[\frac{exp(a)}{exp(b)}=exp(a-b)\]</span></p>
<p>and removing lots of terms gives us:</p>
<p><span class="math display">\[\frac{odds_{i,x_j+1}}{odds_i}=exp\left(\beta_{j}(x_{i,j}+1)-\beta_{j}x_{i,j}\right)=exp\left(\beta_j\right)\]</span></p>
<p>And we end up with something simple like <span class="math inline">\(\exp(\beta_j)\)</span>.
So a change of <span class="math inline">\(x_j\)</span> by one unit changes the odds ratio (multiplicatively) by a factor of <span class="math inline">\(\exp(\beta_j)\)</span>.
We could also interpret it this way:
A change in <span class="math inline">\(x_j\)</span> by one unit changes the log odds ratio by <span class="math inline">\(\beta_j\)</span> units, but most people do the former because thinking about the <span class="math inline">\(log()\)</span> of something is known to be hard on the brain.
Interpreting the odds ratio already needs a bit of getting used to.
For example if you have odds of 2, it means that the probability for <span class="math inline">\(y_i=1\)</span> is twice as big as <span class="math inline">\(y_i=0\)</span>.
If you have a <span class="math inline">\(\beta_j\)</span> (=odds ratio) of <span class="math inline">\(0.7\)</span>, then an increase in the respective <span class="math inline">\(x_j\)</span> by one unit multiplies the odds by <span class="math inline">\(\exp(0.7)\approx2\)</span> and the odds change to 4.
But usually you don’t deal with the odds and only interpret the <span class="math inline">\(\beta\)</span>’s as the odds ratios.
Because for actually calculating the odds you would need to set a value for each feature <span class="math inline">\(x_j\)</span>, which only makes sense if you want to look at one specific instance of your dataset.</p>
<p>Here are the interpretations for the logistic regression model with different feature types:</p>
<ul>
<li>Numerical feature: For an increase of one unit of the feature <span class="math inline">\(x_{j}\)</span>, the estimated odds change (multiplicatively) by a factor of <span class="math inline">\(\exp(\beta_{j})\)</span></li>
<li>Binary categorical feature: One of the two values of the feature is the reference level (in some languages the one that was coded in 0).
A change of the feature <span class="math inline">\(x_{j}\)</span> from the reference level to the other level changes the estimated odds (multiplicatively) by a factor of <span class="math inline">\(\exp(\beta_{j})\)</span></li>
<li>Categorical feature with many levels: One solution to deal with many possible feature values is to one-hot-encode them, meaning each level gets its own column.
From a categorical feature with L levels, you only need L-1 columns, otherwise it is over-parameterised. The interpretation for each level is then according to the binary features.</li>
<li>Intercept <span class="math inline">\(\beta_{0}\)</span>: Given all numerical features are zero and the categorical features are at the reference level, the estimated odds are <span class="math inline">\(\exp(\beta_{0})\)</span>.
The interpretation of <span class="math inline">\(\beta_{0}\)</span> is usually not relevant.</li>
</ul>
</div>
<div id="example" class="section level3">
<h3><span class="header-section-number">5.2.4</span> Example</h3>
<p>We use the logistic regression model to predict <a href="cervical.html#cervical">cervical cancer</a> given some risk factors.
The following table shows the estimate weights, the associated odds ratios and the standard error of the estimates:</p>
<table>
<caption><span id="tab:logistic-example">TABLE 5.1: </span>The results from fitting a logistic regression model on the cervical cancer dataset. Shown are the features used in the model, their estimated weights and according odds ratios and the standard errors of the estimated weights.</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">Weight</th>
<th align="right">Odds ratio</th>
<th align="right">Std. Error</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Intercept</td>
<td align="right">2.91</td>
<td align="right">18.36</td>
<td align="right">0.32</td>
</tr>
<tr class="even">
<td>Hormonal contraceptives y/n</td>
<td align="right">0.12</td>
<td align="right">1.12</td>
<td align="right">0.30</td>
</tr>
<tr class="odd">
<td>Smokes y/n</td>
<td align="right">-0.26</td>
<td align="right">0.77</td>
<td align="right">0.37</td>
</tr>
<tr class="even">
<td>Num. of pregnancies</td>
<td align="right">-0.04</td>
<td align="right">0.96</td>
<td align="right">0.10</td>
</tr>
<tr class="odd">
<td>Num. of diagnosed STDs</td>
<td align="right">-0.82</td>
<td align="right">0.44</td>
<td align="right">0.33</td>
</tr>
<tr class="even">
<td>Intrauterine device y/n</td>
<td align="right">-0.62</td>
<td align="right">0.54</td>
<td align="right">0.40</td>
</tr>
</tbody>
</table>
<p>Interpretation of a numerical feature (‘Num. of diagnosed STDs’):
An increase of the number of diagnosed STDs (sexually transmitted diseases) changes (decreases) the odds for cancer vs. no cancer multiplicatively by 0.44, given all other features stay the same.
Keep in mind that correlation does not imply causation.
No recommendation here to get STDs.</p>
<p>Interpretation of a categorical feature (‘Hormonal contraceptives y/n’):
For women with hormonal contraceptives, the odds for cancer vs. no cancer are by a factor of 1.12 higher, compared to women without hormonal contraceptives, given all other features stay the same.</p>
<p>Again as in the linear models, the interpretations are always coming with the clause that ‘all other features stay the same’.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="limo.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="tree.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/christophM/interpretable-ml-book/edit/master/04.3-interpretable-logistic.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
